{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Lab 6: Experiment with Context-Free Grammars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from pprint import pprint\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1. Examine Grammar Rules\n",
    "\n",
    "Open the `atis3.cfg` file and examine its content. \n",
    "\n",
    "Start symbol is defined in the first two lines: \"# Start symbols \\n Top\"\n",
    "\n",
    "Lines after the comment line \"# Phrasal rules\" and before \"# Lexical rules\" are rules for non-terminal symbols, for example: `NP -> NP PP`. \n",
    "\n",
    "Lines after the comment line \"# Lexical rules\" are rules for terminal symbols, for example: `NP -> aircraft`.\n",
    "\n",
    "**Task**: Count the number of rules whose left-hand side symbol is `NP` (inlucding both phrasal and lexical rules).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP rules count: 276\n"
     ]
    }
   ],
   "source": [
    "NP_count = 0\n",
    "\n",
    "with open('atis3.cfg', 'r') as f:\n",
    "    ### START YOUR CODE ###\n",
    "     for line in f:\n",
    "        split = line.split()\n",
    "        if len(split) == 0:\n",
    "            continue\n",
    "        if split[0] == 'NP':\n",
    "            NP_count += 1\n",
    "    ### END YOUR CODE ###\n",
    "\n",
    "# Test result\n",
    "print('NP rules count:', NP_count)\n",
    "\n",
    "# You should expect to see:\n",
    "# NP rules count: 276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Parse Grammar Rules\n",
    "\n",
    "Define the function `parse_rules` that reads a string of one grammar rule and returns a tuple of two strings: left-hand side and right-hand side of the rule.\n",
    "\n",
    "**Note**:\n",
    "- The left hand side is a `str` and the right hand side is a `tuple` of `str`. Thus, in cases of lexical rules, the right-hand side tuple will have only one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule: NP -> DET N\n",
      "lhs: NP\n",
      "rhs: ('DET', 'N')\n",
      "\n",
      "rule: NP -> aircraft\n",
      "lhs: NP\n",
      "rhs: ('aircraft',)\n"
     ]
    }
   ],
   "source": [
    "def parse_rule(rule: str) -> Tuple[str, Tuple[str]]:\n",
    "    ### START YOUR CODE ###\n",
    "    split = rule.split(\"->\")\n",
    "    lhs = split[0].strip()\n",
    "    rhs = tuple(split[1].strip().split())\n",
    "    ### END YOUR CODE ###\n",
    "    return lhs, rhs\n",
    "\n",
    "# Test result\n",
    "rule1 = 'NP -> DET N'\n",
    "print('rule:', rule1)\n",
    "lhs, rhs = parse_rule(rule1)\n",
    "print('lhs:', lhs)\n",
    "print('rhs:', rhs)\n",
    "\n",
    "print()\n",
    "rule2 = 'NP -> aircraft'\n",
    "print('rule:', rule2)\n",
    "lhs, rhs = parse_rule(rule2)\n",
    "print('lhs:', lhs)\n",
    "print('rhs:', rhs)\n",
    "\n",
    "# You should expect to see:\n",
    "# rule: NP -> DET N\n",
    "# lhs: NP\n",
    "# rhs: ('DET', 'N')\n",
    "\n",
    "# rule: NP -> aircraft\n",
    "# lhs: NP\n",
    "# rhs: ('aircraft',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next**, integrate the above functions to the `CFG` class. \n",
    "\n",
    "**Notes**:\n",
    "- In the class method `read_rules`, read the rules line by line and parse them using the `parse_rules` function.\n",
    "- The class member `lhs_to_rules` is a dictionary mapping the left-hand side symbol (`str`) to the complete rule returned by `parse_rules` function.\n",
    "- Similarly, `rhs_to_rules` maps the right-hand side (`tuple`) to the complete rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG(object):\n",
    "    def __init__(self, grammar_file: io.TextIOWrapper):\n",
    "        self.rhs_to_rules = defaultdict(list)\n",
    "        self.lhs_to_rules = defaultdict(list)\n",
    "        self.startsymbol = None\n",
    "        self.read_rules(grammar_file)\n",
    "\n",
    "    def read_rules(self, grammar_file: io.TextIOWrapper):\n",
    "        for line in grammar_file:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(\"#\"):\n",
    "                if \"->\" in line:\n",
    "                    ### START YOUR CODE ###\n",
    "                    lhs, rhs = self.parse_rule(line)\n",
    "                    self.lhs_to_rules[lhs].append((rhs, line))\n",
    "                    self.rhs_to_rules[rhs].append((lhs, line))\n",
    "                    ### END YOUR CODE ###\n",
    "                else:\n",
    "                    startsymbol = line.strip()\n",
    "                    self.startsymbol = startsymbol\n",
    "    \n",
    "    def parse_rule(self, rule: str) -> Tuple[str, Tuple[str]]:\n",
    "        ### START YOUR CODE ###\n",
    "        # Copy from the previous cell\n",
    "        split = rule.split(\"->\")\n",
    "        lhs = split[0].strip()\n",
    "        rhs = tuple(split[1].strip().split())\n",
    "        ### END YOUR CODE ###\n",
    "        return lhs, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhs_to_rules: 852\n",
      "lhs_to_rules: 300\n",
      "startsymbol: TOP\n",
      "\n",
      "# of \"NP -> *\": 276\n",
      "# of \"* -> aircraft\": 2\n",
      "\n",
      "all rules for \"* -> aircraft\":\n",
      "('AIRCRAFT', 'AIRCRAFT -> aircraft')\n",
      "('NP', 'NP -> aircraft')\n"
     ]
    }
   ],
   "source": [
    "# Test result\n",
    "with open('atis3.cfg', 'r') as f:\n",
    "    cfg = CFG(f)\n",
    "    print('rhs_to_rules:', len(cfg.rhs_to_rules))\n",
    "    print('lhs_to_rules:', len(cfg.lhs_to_rules))\n",
    "    print('startsymbol:', cfg.startsymbol)\n",
    "\n",
    "    print()\n",
    "    print('# of \"NP -> *\":', len(cfg.lhs_to_rules['NP']))\n",
    "    print('# of \"* -> aircraft\":', len(cfg.rhs_to_rules[('aircraft',)]))\n",
    "\n",
    "    print()\n",
    "    print('all rules for \"* -> aircraft\":')\n",
    "    for rule in cfg.rhs_to_rules[('aircraft',)]:\n",
    "        print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that `rhs_to_rules` provides a convenient way to find all rules that have a specific right-hand side symbol.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T3. CKY Recognition\n",
    "\n",
    "We first implement the CKY recognition algorithm cell by cell.\n",
    "\n",
    "**Note**\n",
    "- First, the **super-diagonal** elements (directly above the diagonal elements), i.e., `table[i, i+1]`, correspond to the span of length 1 in the input sentence.\n",
    "- We can retrieve their rules from the `rhs_to_rules` dictionary, using the terminal symbol as the key (in tuple of length 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[], ['FLIGHTS', 'NP'], [], [], [], [], []],\n",
      " [[], [], ['FROM', 'PP'], [], [], [], []],\n",
      " [[], [], [], ['NP'], [], [], []],\n",
      " [[], [], [], [], ['TO', 'X'], [], []],\n",
      " [[], [], [], [], [], ['CLEVELAND', 'NP'], []],\n",
      " [[], [], [], [], [], [], ['PUN']],\n",
      " [[], [], [], [], [], [], []]]\n"
     ]
    }
   ],
   "source": [
    "tokens = 'flights from miami to cleveland .'.split()\n",
    "n = len(tokens)\n",
    "\n",
    "# Initialize the table\n",
    "table = [[[] for _ in range(n+1)] for _ in range(n+1)]\n",
    "\n",
    "# Fill the super-diagonal elements\n",
    "for j in range(n):\n",
    "    ### START YOUR CODE ###\n",
    "    for lhs, rhs in cfg.rhs_to_rules[(tokens[j],)]:\n",
    "        table[j][j+1].append(lhs)\n",
    "    ### END YOUR CODE ###\n",
    "\n",
    "\n",
    "# Test result\n",
    "pprint(table)\n",
    "\n",
    "# You should expect to see:\n",
    "# [[[], ['FLIGHTS', 'NP'], [], [], [], [], []],\n",
    "#  [[], [], ['FROM', 'PP'], [], [], [], []],\n",
    "#  [[], [], [], ['NP'], [], [], []],\n",
    "#  [[], [], [], [], ['TO', 'X'], [], []],\n",
    "#  [[], [], [], [], [], ['CLEVELAND', 'NP'], []],\n",
    "#  [[], [], [], [], [], [], ['PUN']],\n",
    "#  [[], [], [], [], [], [], []]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next**, go through each cell `[i,j]` in the rest of the table, and find all non-terminal symbols.\n",
    "\n",
    "**Note**\n",
    "- Each table cell `[i,j]` is initialized as an empty list. \n",
    "- Go through each item in `rhs_to_rules`, and check if a rule satisfies the CKY recognition condition. If so, append the entire rule to the cell `[i,j]`.\n",
    "- For simplicity, we make each cell a list of unique rules to avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the rest of the table\n",
    "\n",
    "for j in range(2, n+1):\n",
    "    for i in range(j-2, -1, -1):\n",
    "        for k in range(i+1, j):\n",
    "            ### START YOUR CODE ###\n",
    "            for B in table[i][k]:\n",
    "                for C in table[k][j]:\n",
    "                    for lhs, rhs in cfg.rhs_to_rules[(B, C)]:\n",
    "                        table[i][j].append(lhs)\n",
    "            ### END YOUR CODE ###\n",
    "        table[i][j] = list(set(table[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[],\n",
      " ['FLIGHTS', 'NP'],\n",
      " ['VPBAR', 'FRAG', 'NP', 'SQBAR'],\n",
      " ['FRAG', 'FRAGBAR', 'SQBAR', 'VPBAR', 'NPBAR', 'NP'],\n",
      " [],\n",
      " ['FRAG', 'FRAGBAR', 'SQBAR', 'VPBAR', 'NPBAR', 'NP'],\n",
      " ['TOP']]\n"
     ]
    }
   ],
   "source": [
    "# Test result\n",
    "pprint(table[0])\n",
    "\n",
    "# You should see the following output:\n",
    "# [[],\n",
    "#  ['FLIGHTS', 'NP'],\n",
    "#  ['NP', 'SQBAR', 'VPBAR', 'FRAG'],\n",
    "#  ['NPBAR', 'FRAGBAR', 'NP', 'SQBAR', 'VPBAR', 'FRAG'],\n",
    "#  [],\n",
    "#  ['NPBAR', 'FRAGBAR', 'NP', 'SQBAR', 'VPBAR', 'FRAG'],\n",
    "#  ['TOP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly**, after the table is filled, we can check if the start symbol is in cell `[0,n]`. \n",
    "\n",
    "If so, the input sentence is recognized by the grammar, i.e., grammatical; otherwise not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string is grammatical\n"
     ]
    }
   ],
   "source": [
    "if cfg.startsymbol in table[0][n]:\n",
    "    print('The input string is grammatical')\n",
    "else:\n",
    "    print('The input string is not grammatical')\n",
    "\n",
    "# You should see the following output:\n",
    "# The input string is grammatical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, \"flights from miami to cleveland .\" is grammatical. \n",
    "\n",
    "You can try scrambling the sentence to see if the output changes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T4. Integrate into the CKY class\n",
    "\n",
    "Integrate the above code to the `is_grammatical` method of `CKY` class, which takes a list of tokens as input and returns a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKY(object):\n",
    "    def __init__(self, cfg: CFG):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def is_grammatical(self, tokens: List[str]) -> bool:\n",
    "        ### START YOUR CODE ###\n",
    "        pass\n",
    "        ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test CKY class\n",
    "with open('atis3.cfg', 'r') as f:\n",
    "    cfg = CFG(f)\n",
    "    cky = CKY(cfg)\n",
    "    print(cky.is_grammatical('flights from miami to cleveland .'.split()))\n",
    "    print(cky.is_grammatical('miami flights cleveland from to .'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! \n",
    "\n",
    "You have implemented the bare-bones CKY algorithm for recognizing sentences using a CFG.\n",
    "\n",
    "It is not yet a complete CKY parser, as it does not return the parse tree. In order to do that, you need to store backpointers in the table, which is a bit more complex.\n",
    "\n",
    "For example, you can replace the table entry with a `dict` whose key is the LHS of rule, and the value is a tuple of two RHS symbols (and their cell indices)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
