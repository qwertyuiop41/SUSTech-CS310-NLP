{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Lab 13: Explore Question-Answering Models and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will practice with running pretrained models on question-answering tasks. The we demonstrate with is `distilbert-base-uncased`, which is a smaller version of BERT.\n",
    "\n",
    "We will use the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) datast provided in the [Datasets](https://github.com/huggingface/datasets) library. Make sure to install the library:\n",
    "\n",
    "```bash\n",
    "pip install datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1. Explore the SQuAD dataset\n",
    "\n",
    "First, let's load the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5890d2143f06495fac25a87783a63c34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b44bdddaf51b4c8098bb5290dff8de1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "squad_dataset = load_dataset('./squad/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `squad_dataset` object is a `DefaultDict` that contains keys for the train and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a data instance, you can specify the split and index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that teh answer is indicated by its span start index (at character `515`) in the passage text. \n",
    "\n",
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_elements(squad_dataset[\"train\"], num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Preprocess the data\n",
    "\n",
    "Before we feed the data to a model for fine-tuning, there is some preprocessing needed: \n",
    "- Tokenize the input text\n",
    "- Put it in the format expected by the model\n",
    "- Generate other inputs the model requires\n",
    "\n",
    "To do all of this, we need to instantiate a tokenizer that is compatible with the model we want to use, i.e., `distilbert-base-uncased`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"./distilbert-base-uncased\" # If loaded locally, make sure you have the model downloaded first\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly call this tokenizer on two sentences (e.g., question and context):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('Architecturally, the school has a Catholic character.', 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step in QA is to deal with very **long documents**. If longer than the maximum input size of model, then removing part of context might result in losing the answer.\n",
    "\n",
    "To handle this, we will allow a long document to give several input *features*, each of length shorter than the maximum size. \n",
    "\n",
    "Also, in case the answer is split between two features, we allow some overlap between features, controlled by `doc_stride`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine on one long example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(squad_dataset[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = squad_dataset[\"train\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without truncation, its length is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer(example['question'], example['context'])['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we truncate, the resulting length is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never want to truncate the question, so we specify `truncation='only_second`. \n",
    "\n",
    "Now, we further tell the tokenizer to return the overlaping features, by setting `return_overflowing_tokens=True` and `stride=doc_stride`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "\n",
    "print([len(x) for x in tokenized_example[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the two features decoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    pprint(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we nned to find out in which of the two features the answer is, and where exactly it starts and ends.\n",
    "\n",
    "Thankfully, the tokenizer can help us by returning the `offset_mapping` that gives the start and end character of each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "print(offsets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output, the very first token (`[CLS]`) has `(0, 0)` because it doesn't correspond to any part of the question/answer.\n",
    "\n",
    "The second token corresponds to the span from character 0 to 3 in the context, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens(token_id))\n",
    "\n",
    "token_offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(example[\"question\"][token_offsets[0]:token_offsets[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on to the next step, we just have to distinguish between the offsets for `question` and those for `context`. The `sequence_ids` method can be helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "\n",
    "print('len(sequence_ids):', len(sequence_ids))\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns None for the special tokens; then `0` for tokens from the first sequence (i.e., the `question`), and `1` for tokens from the second sequence (i.e., the `context`).\n",
    "\n",
    "It tells us that we need to find the span of answer among all `1` tokens.\n",
    "\n",
    "Now, we are ready to use `offset_mapping` to find the position of the start and end tokens of the `answer` in a given feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = example[\"answers\"]\n",
    "ans_start = answers[\"answer_start\"][0]\n",
    "ans_end = ans_start + len(answers[\"text\"][0])\n",
    "\n",
    "print(answers)\n",
    "print('ans_start:', ans_start)\n",
    "print('end_char:', ans_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `token_start_index` and `token_end_index` be the initial search range for the answer span, initialize them properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position of the first `1` token\n",
    "### START YOUR CODE ###\n",
    "# token_start_index = None\n",
    "token_start_index = tokenized_example.char_to_token(0)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "print('token_start_index:', token_start_index)\n",
    "print('offsets[token_start_index]:', offsets[token_start_index])\n",
    "# Expected output\n",
    "# token_start_index: 16\n",
    "# offsets[token_start_index]: (0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position of the last `1` token\n",
    "### START YOUR CODE ###\n",
    "# token_end_index = None\n",
    "token_end_index = tokenized_example.char_to_token(len(example[\"context\"]) - 1)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "print('token_end_index:', token_end_index)\n",
    "print('offsets[token_end_index]:', offsets[token_end_index])\n",
    "# Expected output\n",
    "# token_end_index: 382\n",
    "# offsets[token_end_index]: (1665, 1669)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, detect if `ans_start` and `ans_end` is within the initial search range. \n",
    "\n",
    "If they do, then find the start and end indices of tokens, whose offsets encompass `ans_start` and `ans_end`, repectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "token_start_index = 16\n",
    "token_end_index = 382 # reset\n",
    "\n",
    "# Detect if the answer is within the initial search range\n",
    "### START YOUR CODE ###\n",
    "if None: # Change `None` to your condition\n",
    "    print('The answer is not in this feature.')\n",
    "### END YOUR CODE ###\n",
    "else:\n",
    "    # Find the start and end indices of the tokens, whose offsets encompass the ans_start and ans_end\n",
    "    ### START YOUR CODE ###\n",
    "    start_position = None\n",
    "    end_position = None\n",
    "    for i, (start, end) in enumerate(offsets):\n",
    "        if ans_start >= start and ans_start < end:\n",
    "            start_position = i\n",
    "        if ans_end > start and ans_end <= end:\n",
    "            end_position = i + 1\n",
    "    ### END YOUR CODE ###\n",
    "\n",
    "# Test\n",
    "print(start_position, end_position)\n",
    "print(offsets[start_position], offsets[end_position])\n",
    "\n",
    "# Expected output\n",
    "# 23 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that it is indeed the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
