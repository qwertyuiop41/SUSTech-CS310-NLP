{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Lab 13: Explore Question-Answering Models and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will practice with running pretrained models on question-answering tasks. The we demonstrate with is `distilbert-base-uncased`, which is a smaller version of BERT.\n",
    "\n",
    "We will use the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) datast provided in the [Datasets](https://github.com/huggingface/datasets) library. Make sure to install the library:\n",
    "\n",
    "```bash\n",
    "pip install datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1. Explore the SQuAD dataset\n",
    "\n",
    "First, let's load the SQuAD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach 'squad2' on the Hub (ConnectionError)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset, load_metric\n\u001B[0;32m----> 3\u001B[0m squad_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msquad2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/datasets/load.py:2587\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2582\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[1;32m   2583\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[1;32m   2584\u001B[0m )\n\u001B[1;32m   2586\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[0;32m-> 2587\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset_builder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2588\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2589\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2590\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2591\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2592\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2593\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2594\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2596\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2597\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2598\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2599\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2600\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2601\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2602\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2604\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[1;32m   2605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/datasets/load.py:2259\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001B[0m\n\u001B[1;32m   2257\u001B[0m     download_config \u001B[38;5;241m=\u001B[39m download_config\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m download_config \u001B[38;5;28;01melse\u001B[39;00m DownloadConfig()\n\u001B[1;32m   2258\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mupdate(storage_options)\n\u001B[0;32m-> 2259\u001B[0m dataset_module \u001B[38;5;241m=\u001B[39m \u001B[43mdataset_module_factory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2268\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_require_default_config_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2269\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_custom_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2271\u001B[0m \u001B[38;5;66;03m# Get dataset builder class from the processing script\u001B[39;00m\n\u001B[1;32m   2272\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/datasets/load.py:1910\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1905\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e1, \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m):\n\u001B[1;32m   1906\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1907\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1908\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hugging Face Hub either: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e1)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1909\u001B[0m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1910\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e1 \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1911\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1912\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1913\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1914\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/datasets/load.py:1843\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1834\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001B[39;00m\n\u001B[1;32m   1835\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m   1836\u001B[0m         e,\n\u001B[1;32m   1837\u001B[0m         (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1841\u001B[0m         ),\n\u001B[1;32m   1842\u001B[0m     ):\n\u001B[0;32m-> 1843\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt reach \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hub (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1844\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m404\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n\u001B[1;32m   1845\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt exist on the Hub or cannot be accessed\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mConnectionError\u001B[0m: Couldn't reach 'squad2' on the Hub (ConnectionError)"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "squad_dataset = load_dataset('squad 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `squad_dataset` object is a `DefaultDict` that contains keys for the train and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a data instance, you can specify the split and index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '5733be284776f41900661182',\n 'title': 'University_of_Notre_Dame',\n 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that teh answer is indicated by its span start index (at character `515`) in the passage text. \n",
    "\n",
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>573046d4a23a5019007fd04f</td>\n      <td>Swaziland</td>\n      <td>The Swazi economy is very closely linked to the economy of South Africa, from which it receives over 90% of its imports and to which it sends about 70% of its exports. Swaziland's other key trading partners are the United States and the EU, from whom the country has received trade preferences for apparel exports (under the African Growth and Opportunity Act – AGOA – to the US) and for sugar (to the EU). Under these agreements, both apparel and sugar exports did well, with rapid growth and a strong inflow of foreign direct investment. Textile exports grew by over 200% between 2000 and 2005 and sugar exports increasing by more than 50% over the same period.</td>\n      <td>What percentage of exported goods from Swaziland end up in South Africa?</td>\n      <td>{'text': ['70%'], 'answer_start': [148]}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57280ea3ff5b5019007d9bf6</td>\n      <td>Unicode</td>\n      <td>Rendering software which cannot process a Unicode character appropriately often displays it as an open rectangle, or the Unicode \"replacement character\" (U+FFFD, �), to indicate the position of the unrecognized character. Some systems have made attempts to provide more information about such characters. The Apple's Last Resort font will display a substitute glyph indicating the Unicode range of the character, and the SIL International's Unicode Fallback font will display a box showing the hexadecimal scalar value of the character.</td>\n      <td>What does rendering software display when it can't process a Unicode character?</td>\n      <td>{'text': ['open rectangle, or the Unicode \"replacement character\"'], 'answer_start': [98]}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56f799d2a6d7ea1400e17262</td>\n      <td>Marshall_Islands</td>\n      <td>A number of vessels visiting the islands were attacked and their crews killed. In 1834, Captain DonSette and his crew were killed. Similarly, in 1845 the schooner Naiad punished a native for stealing with such violence that the natives attacked the ship. Later that year a whaler's boat crew were killed. In 1852 the San Francisco-based ships Glencoe and Sea Nymph were attacked and everyone aboard except for one crew member were killed. The violence was usually attributed as a response to the ill treatment of the natives in response to petty theft, which was a common practice. In 1857, two missionaries successfully settled on Ebon, living among the natives through at least 1870.:3</td>\n      <td>On what island did the Missionaries live with citizens of the Marshall Islands?</td>\n      <td>{'text': ['Ebon'], 'answer_start': [632]}</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(squad_dataset[\"train\"], num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Preprocess the data\n",
    "\n",
    "Before we feed the data to a model for fine-tuning, there is some preprocessing needed: \n",
    "- Tokenize the input text\n",
    "- Put it in the format expected by the model\n",
    "- Generate other inputs the model requires\n",
    "\n",
    "To do all of this, we need to instantiate a tokenizer that is compatible with the model we want to use, i.e., `distilbert-base-uncased`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"./distilbert-base-uncased\" # If loaded locally, make sure you have the model downloaded first\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly call this tokenizer on two sentences (e.g., question and context):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [101, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 102, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Architecturally, the school has a Catholic character.', 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step in QA is to deal with very **long documents**. If longer than the maximum input size of model, then removing part of context might result in losing the answer.\n",
    "\n",
    "To handle this, we will allow a long document to give several input *features*, each of length shorter than the maximum size. \n",
    "\n",
    "Also, in case the answer is split between two features, we allow some overlap between features, controlled by `doc_stride`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine on one long example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(squad_dataset[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = squad_dataset[\"train\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without truncation, its length is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "How many wins does the Notre Dame men's basketball team have?\n",
      "The men's basketball team has over 1,600 wins, one of only 12 schools who have reached that mark, and have appeared in 28 NCAA tournaments. Former player Austin Carr holds the record for most points scored in a single game of the tournament with 61. Although the team has never won the NCAA Tournament, they were named by the Helms Athletic Foundation as national champions twice. The team has orchestrated a number of upsets of number one ranked teams, the most notable of which was ending UCLA's record 88-game winning streak in 1974. The team has beaten an additional eight number-one teams, and those nine wins rank second, to UCLA's 10, all-time in wins against the top team. The team plays in newly renovated Purcell Pavilion (within the Edmund P. Joyce Center), which reopened for the beginning of the 2009–2010 season. The team is coached by Mike Brey, who, as of the 2014–15 season, his fifteenth at Notre Dame, has achieved a 332-165 record. In 2009 they were invited to the NIT, where they advanced to the semifinals but were beaten by Penn State who went on and beat Baylor in the championship. The 2010–11 team concluded its regular season ranked number seven in the country, with a record of 25–5, Brey's fifth straight 20-win season, and a second-place finish in the Big East. During the 2014-15 season, the team went 32-6 and won the ACC conference tournament, later advancing to the Elite 8, where the Fighting Irish lost on a missed buzzer-beater against then undefeated Kentucky. Led by NBA draft picks Jerian Grant and Pat Connaughton, the Fighting Irish beat the eventual national champion Duke Blue Devils twice during the season. The 32 wins were the most by the Fighting Irish team since 1908-09.\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer(example['question'], example['context'])['input_ids']))\n",
    "print(example['question'])\n",
    "print(example['context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we truncate, the resulting length is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "384"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never want to truncate the question, so we specify `truncation='only_second`. \n",
    "\n",
    "Now, we further tell the tokenizer to return the overlaping features, by setting `return_overflowing_tokens=True` and `stride=doc_stride`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384, 157]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "\n",
    "print([len(x) for x in tokenized_example[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the two features decoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    pprint(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we nned to find out in which of the two features the answer is, and where exactly it starts and ends.\n",
    "\n",
    "Thankfully, the tokenizer can help us by returning the `offset_mapping` that gives the start and end character of each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "print(offsets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output, the very first token (`[CLS]`) has `(0, 0)` because it doesn't correspond to any part of the question/answer.\n",
    "\n",
    "The second token corresponds to the span from character 0 to 3 in the context, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens(token_id))\n",
    "\n",
    "token_offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(example[\"question\"][token_offsets[0]:token_offsets[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on to the next step, we just have to distinguish between the offsets for `question` and those for `context`. The `sequence_ids` method can be helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "\n",
    "print('len(sequence_ids):', len(sequence_ids))\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns None for the special tokens; then `0` for tokens from the first sequence (i.e., the `question`), and `1` for tokens from the second sequence (i.e., the `context`).\n",
    "\n",
    "It tells us that we need to find the span of answer among all `1` tokens.\n",
    "\n",
    "Now, we are ready to use `offset_mapping` to find the position of the start and end tokens of the `answer` in a given feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "answers = example[\"answers\"]\n",
    "ans_start = answers[\"answer_start\"][0]\n",
    "ans_end = ans_start + len(answers[\"text\"][0])\n",
    "\n",
    "print(answers)\n",
    "print('ans_start:', ans_start)\n",
    "print('end_char:', ans_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `token_start_index` and `token_end_index` be the initial search range for the answer span, initialize them properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the position of the first `1` token\n",
    "### START YOUR CODE ###\n",
    "token_start_index = sequence_ids.index(1) \n",
    "### END YOUR CODE ###\n",
    "\n",
    "print('token_start_index:', token_start_index)\n",
    "print('offsets[token_start_index]:', offsets[token_start_index])\n",
    "# Expected output\n",
    "# token_start_index: 16\n",
    "# offsets[token_start_index]: (0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the position of the last `1` token\n",
    "### START YOUR CODE ###\n",
    "token_end_index = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "print('token_end_index:', token_end_index)\n",
    "print('offsets[token_end_index]:', offsets[token_end_index])\n",
    "# Expected output\n",
    "# token_end_index: 382\n",
    "# offsets[token_end_index]: (1665, 1669)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, detect if `ans_start` and `ans_end` is within the initial search range. \n",
    "\n",
    "If they do, then find the start and end indices of tokens, whose offsets encompass `ans_start` and `ans_end`, repectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "token_start_index = 16\n",
    "token_end_index = 382 # reset\n",
    "\n",
    "# Detect if the answer is within the initial search range\n",
    "### START YOUR CODE ###\n",
    "if not (offsets[token_start_index][0] <= ans_start <= offsets[token_end_index][1] and\n",
    "        offsets[token_start_index][0] <= ans_end <= offsets[token_end_index][1]):\n",
    "    print('The answer is not in this feature.')\n",
    "### END YOUR CODE ###\n",
    "else:\n",
    "    # Find the start and end indices of the tokens, whose offsets encompass the ans_start and ans_end\n",
    "    ### START YOUR CODE ###\n",
    "    start_position = next(i for i, (start, end) in enumerate(offsets) if start == ans_start and ans_start< end)\n",
    "    end_position = next(i for i, (start, end) in enumerate(offsets) if start < ans_end and ans_end== end)\n",
    "\n",
    "    ### END YOUR CODE ###\n",
    "\n",
    "# Test\n",
    "print(start_position, end_position)\n",
    "print(offsets[start_position], offsets[end_position])\n",
    "\n",
    "# Expected output\n",
    "# 23 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that it is indeed the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
