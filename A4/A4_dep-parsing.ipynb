{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Assignment 4. Dependency Parsing\n",
    "\n",
    "**Total points**: 50\n",
    "\n",
    "In this assignment, you will train feed-forward neural network-based dependency parser and evaluate its performance on the provided treebank dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Data and Generate Training Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import defaultdict\n",
    "from dep_utils import conll_reader\n",
    "\n",
    "\n",
    "class State(object):\n",
    "    def __init__(self, sentence):\n",
    "        self.stack = []\n",
    "        self.buffer = []\n",
    "        if sentence:\n",
    "            self.buffer = list(reversed(sentence))\n",
    "        self.deps = set()\n",
    "\n",
    "    def shift(self):\n",
    "        ### START YOUR CODE ###\n",
    "        # print(\"shift\")\n",
    "        if self.buffer:\n",
    "            buffer_out=self.buffer.pop(-1)\n",
    "            self.stack.append(buffer_out)\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def left_arc(self, label: str):\n",
    "        assert len(self.stack) >= 2\n",
    "        ### START YOUR CODE ###\n",
    "        dependent = self.stack.pop(-2)\n",
    "        head = self.stack[-1]\n",
    "        self.deps.add((head, dependent, label))\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def right_arc(self, label: str):\n",
    "        assert len(self.stack) >= 2\n",
    "        ### START YOUR CODE ###\n",
    "        dependent = self.stack.pop()\n",
    "        head = self.stack[-1]\n",
    "        self.deps.add((head, dependent, label))\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"({},{},{})\".format(self.stack, self.buffer, self.deps)\n",
    "\n",
    "\n",
    "class RootDummy(object):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.id = 0\n",
    "        self.deprel = None\n",
    "    def __repr__(self):\n",
    "        return \"<ROOT>\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Re-use the code from Lab 7\n",
    "def get_training_instances(dep_tree):\n",
    "    deprels = dep_tree.deprels\n",
    "\n",
    "\n",
    "    word_ids = list(deprels.keys())\n",
    "\n",
    "    state = State(word_ids)\n",
    "    state.stack.append(0)  # ROOT\n",
    "\n",
    "    childcount = defaultdict(int)\n",
    "    for _, rel in deprels.items():\n",
    "        childcount[rel.head] += 1\n",
    "\n",
    "    seq = []\n",
    "    while len(state.buffer) > 0 or len(state.stack) > 1:\n",
    "\n",
    "        if state.stack[-1] == 0:\n",
    "            seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "            state.shift()\n",
    "            continue\n",
    "\n",
    "        stack_top1 = deprels[state.stack[-1]]\n",
    "        if state.stack[-2] == 0:\n",
    "            stack_top2 = RootDummy()\n",
    "        else:\n",
    "            stack_top2 = deprels[state.stack[-2]]\n",
    "        if stack_top2.head == stack_top1.id and childcount[stack_top2.id] == 0:\n",
    "            # Left-Arc\n",
    "            relation = stack_top2.deprel\n",
    "            seq.append((copy.deepcopy(state), (\"left_arc\", relation)))\n",
    "            state.left_arc(relation)\n",
    "            childcount[stack_top2.id] -= 1\n",
    "            childcount[stack_top1.id] -= 1\n",
    "        elif stack_top1.head == stack_top2.id and childcount[stack_top1.id] == 0:\n",
    "            # Right-Arc\n",
    "            relation = stack_top1.deprel\n",
    "            seq.append((copy.deepcopy(state), (\"right_arc\", relation)))\n",
    "            state.right_arc(relation)\n",
    "            childcount[stack_top1.id] -= 1\n",
    "            childcount[stack_top2.id] -= 1\n",
    "        else:\n",
    "            # Shift\n",
    "            seq.append((copy.deepcopy(state), (\"shift\", None)))\n",
    "            state.shift()\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    seq.append((copy.deepcopy(state), (\"done\", None)))\n",
    "\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Implement the Feature Extractor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from dep_utils import DependencyTree\n",
    "\n",
    "\n",
    "def feature_extract(\n",
    "        tree: DependencyTree,\n",
    "        word_vectors: dict,\n",
    "        pos_vectors: dict,):\n",
    "    instances = get_training_instances(tree)\n",
    "    for state, action in instances:\n",
    "        if action[0] == \"done\":\n",
    "            break\n",
    "        if len(state.stack) >= 3:\n",
    "            stack = state.stack[-3:]\n",
    "        else:\n",
    "            stack= state.stack + [-1] * (3 - len(state.stack))\n",
    "        if len(state.buffer) >= 3:\n",
    "            buffer = state.buffer[-3:]\n",
    "        else:\n",
    "            buffer= state.buffer + [-1] * (3 - len(state.buffer))\n",
    "\n",
    "        stack_idxes = []\n",
    "        stack_pos_idxes = []\n",
    "        buffer_idxes = []\n",
    "        buffer_pos_idxes = []\n",
    "        for s in stack:\n",
    "            if s == -1:\n",
    "                stack_idxes.extend(word_vectors[\"<NULL>\"])\n",
    "                stack_pos_idxes.extend(pos_vectors[\"<NULL>\"])\n",
    "            elif s == 0:\n",
    "                stack_idxes.extend(word_vectors[\"<ROOT>\"])\n",
    "                stack_pos_idxes.extend(pos_vectors[\"<ROOT>\"])\n",
    "            else:\n",
    "                if tree.deprels[s].word in word_vectors.keys():\n",
    "                    stack_idxes.extend(word_vectors[tree.deprels[s].word])\n",
    "                else:\n",
    "                    stack_idxes.extend(word_vectors[\"<NULL>\"])\n",
    "                if tree.deprels[s].pos in pos_vectors.keys():\n",
    "                    stack_pos_idxes.extend(pos_vectors[tree.deprels[s].pos])\n",
    "                else:\n",
    "                    stack_pos_idxes.extend(pos_vectors[\"<NULL>\"])\n",
    "\n",
    "        for b in buffer:\n",
    "            if b == -1:\n",
    "                buffer_idxes.extend(word_vectors[\"<NULL>\"])\n",
    "                buffer_pos_idxes.extend(pos_vectors[\"<NULL>\"])\n",
    "            elif b == 0:\n",
    "                buffer_idxes.extend(word_vectors[\"<ROOT>\"])\n",
    "                buffer_pos_idxes.extend(pos_vectors[\"<ROOT>\"])\n",
    "            else:\n",
    "                if tree.deprels[b].word in word_vectors.keys():\n",
    "                    buffer_idxes.extend(word_vectors[tree.deprels[b].word])\n",
    "                else:\n",
    "                    buffer_idxes.extend(word_vectors[\"<NULL>\"])\n",
    "                if tree.deprels[b].pos in pos_vectors.keys():\n",
    "                    buffer_pos_idxes.extend(pos_vectors[tree.deprels[b].pos])\n",
    "                else:\n",
    "                    buffer_pos_idxes.extend(pos_vectors[\"<NULL>\"])\n",
    "        # concatenate all index to get word vectors\n",
    "        data_vector = torch.tensor(stack_idxes + buffer_idxes + stack_pos_idxes + buffer_pos_idxes)\n",
    "\n",
    "    return data_vector,action\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train.conll:\n",
      "39832 trees read.\n",
      "In dev.conll:\n",
      "1700 trees read.\n",
      "In test.conll:\n",
      "2416 trees read.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "print(\"In train.conll:\")\n",
    "with open(\"data/train.conll\") as f:\n",
    "    train_trees = list(conll_reader(f))\n",
    "print(f\"{len(train_trees)} trees read.\")\n",
    "\n",
    "print(\"In dev.conll:\")\n",
    "with open(\"data/dev.conll\") as f:\n",
    "    dev_trees = list(conll_reader(f))\n",
    "print(f\"{len(dev_trees)} trees read.\")\n",
    "\n",
    "print(\"In test.conll:\")\n",
    "with open(\"data/test.conll\") as f:\n",
    "    test_trees = list(conll_reader(f))\n",
    "print(f\"{len(test_trees)} trees read.\")\n",
    "\n",
    "relation_counter = Counter()\n",
    "for tree in train_trees:\n",
    "    for item in tree.deprels.values():\n",
    "        relation_counter[item.deprel] += 1\n",
    "\n",
    "word_counter = Counter()\n",
    "for tree in train_trees:\n",
    "    for item in tree.words():\n",
    "        word_counter[item] += 1\n",
    "\n",
    "pos_counter = Counter()\n",
    "for tree in train_trees:\n",
    "    for item in tree.pos():\n",
    "        pos_counter[item] += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocab size: 44392\n",
      "POS vocab size: 48\n",
      "Action vocab size: 79\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size=len(word_counter)+2\n",
    "relation_num=len(relation_counter)\n",
    "pos_size=len(pos_counter)+2\n",
    "\n",
    "\n",
    "# 定义词汇量大小和词向量维度\n",
    "embedding_dim = 50\n",
    "\n",
    "# 使用均匀分布初始化词向量\n",
    "word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "word_embeddings.weight.data.uniform_(-0.1 + 1e-5, 0.1 - 1e-5)  # 在[-0.1, 0.1]范围内均匀分布\n",
    "pos_embeddings = nn.Embedding(pos_size, embedding_dim)\n",
    "pos_embeddings.weight.data.uniform_(-0.1 + 1e-5, 0.1 - 1e-5)\n",
    "\n",
    "null_index = 0\n",
    "root_index = 1\n",
    "word_embeddings.weight.data[null_index] = torch.tensor(-0.1)\n",
    "word_embeddings.weight.data[root_index] = torch.tensor(0.1)\n",
    "\n",
    "pos_embeddings.weight.data[null_index] = torch.tensor(-0.1)\n",
    "pos_embeddings.weight.data[root_index] = torch.tensor(0.1)\n",
    "\n",
    "\n",
    "word_vocab = {\"<NULL>\": -1, \"<ROOT>\": 0}\n",
    "word_vectors = {\"<NULL>\":word_embeddings.weight.data[null_index].tolist(),\"<ROOT>\": word_embeddings.weight.data[root_index].tolist()}\n",
    "pos_vocab = {\"<NULL>\": -1, \"<ROOT>\": 0}\n",
    "pos_vectors = {\"<NULL>\":pos_embeddings.weight.data[null_index].tolist(),\"<ROOT>\":pos_embeddings.weight.data[root_index].tolist()}\n",
    "\n",
    "\n",
    "index = 1  # 从索引 1 开始\n",
    "for word, count in word_counter.most_common():\n",
    "    word_vocab[word] = index\n",
    "    word_embedding = word_embeddings.weight.data[index].tolist()\n",
    "    word_vectors[word]=(word_embedding)\n",
    "    index += 1\n",
    "\n",
    "index = 1  # 从索引 1 开始\n",
    "for pos, count in pos_counter.most_common():\n",
    "    pos_vocab[pos] = index\n",
    "    pos_embedding = pos_embeddings.weight.data[index].tolist()\n",
    "    pos_vectors[pos]=(pos_embedding)\n",
    "    index += 1\n",
    "\n",
    "action_vocab = {}\n",
    "action_vocab[(\"right_arc\", \"root\")] = 0\n",
    "action_vocab[(\"shift\", None)] = 1\n",
    "action_vocab[('done', None)]=2\n",
    "index=3\n",
    "for rel,count in relation_counter.most_common():\n",
    "    if rel == \"root\":\n",
    "        continue\n",
    "    action_vocab[(\"left_arc\", rel)] = index\n",
    "    index+=1\n",
    "    action_vocab[(\"right_arc\", rel)] = index\n",
    "    index+=1\n",
    "\n",
    "\n",
    "print(f\"Word vocab size: {len(word_vocab)}\")\n",
    "print(f\"POS vocab size: {len(pos_vocab)}\")\n",
    "print(f\"Action vocab size: {len(action_vocab)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.0745, -0.0161, -0.0628, -0.0883,  0.0488, -0.0656,\n",
      "         0.0749, -0.0987,  0.0494, -0.0593, -0.0508,  0.0150,  0.0687, -0.0580,\n",
      "         0.0120,  0.0388, -0.0362,  0.0031, -0.0363,  0.0921,  0.0031, -0.0253,\n",
      "         0.0389,  0.0870,  0.0698, -0.0687,  0.0085,  0.0377,  0.0865,  0.0039,\n",
      "        -0.0469, -0.0062,  0.0829,  0.0998,  0.0346, -0.0943,  0.0204,  0.0665,\n",
      "         0.0149, -0.0654, -0.0252, -0.0850,  0.0929, -0.0892,  0.0353, -0.0690,\n",
      "         0.0504, -0.0381,  0.0367, -0.0260, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000, -0.0367, -0.0421,\n",
      "         0.0079, -0.0375,  0.0228, -0.0276, -0.0506, -0.0549,  0.0977,  0.0359,\n",
      "         0.0265,  0.0792, -0.0824,  0.0522, -0.0962,  0.0291,  0.0461,  0.0377,\n",
      "        -0.0737, -0.0732,  0.0192, -0.0342,  0.0988,  0.0137,  0.0028, -0.0687,\n",
      "        -0.0222, -0.0796, -0.0764, -0.0516, -0.0541,  0.0284,  0.0119, -0.0105,\n",
      "         0.0362,  0.0480, -0.0141,  0.0573,  0.0594, -0.0246,  0.0616,  0.0060,\n",
      "        -0.0312, -0.0432,  0.0618, -0.0940, -0.0920, -0.0997, -0.0211, -0.0224,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n",
      "        -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000])\n",
      "('done', None)\n"
     ]
    }
   ],
   "source": [
    "# train_data = []\n",
    "# train_truth = []\n",
    "# train_data, train_truth = feature_extract(\n",
    "#     train_trees,\n",
    "#     word_vectors,\n",
    "#     pos_vectors,\n",
    "#     action_vocab,\n",
    "# )\n",
    "\n",
    "for tree in train_trees:\n",
    "    feature,action=feature_extract(tree,word_vectors,pos_vectors)\n",
    "    print(feature)\n",
    "    print(action)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement the scoring function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ScoringFunction(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ScoringFunction, self).__init__()\n",
    "\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, features):\n",
    "        hidden_output = self.hidden_layer(features)\n",
    "        hidden_output = self.activation(hidden_output)\n",
    "        scores = self.output_layer(hidden_output)\n",
    "        scores = self.softmax(scores)\n",
    "        return scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Parser(nn.Module):\n",
    "    def __init__(self,  scoring_function):\n",
    "        super().__init__()\n",
    "        self.scoring_function = scoring_function\n",
    "\n",
    "    def forward(self, tree):\n",
    "\n",
    "        feature,action=feature_extract(tree,word_vectors,pos_vectors)\n",
    "\n",
    "        scores = self.scoring_function(feature)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def parse_sentence(self, sentence):\n",
    "        state = State(sentence)\n",
    "        state.stack.append(0)\n",
    "        while len(state.buffer) > 0 or len(state.stack) > 1:\n",
    "            if len(state.stack) >= 3:\n",
    "                stack = state.stack[-3:]\n",
    "            else:\n",
    "                stack= state.stack + [-1] * (3 - len(state.stack))\n",
    "            if len(state.buffer) >= 3:\n",
    "                buffer = state.buffer[-3:]\n",
    "            else:\n",
    "                buffer= state.buffer + [-1] * (3 - len(state.buffer))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_tags = []\n",
    "for tree in train_trees:\n",
    "    feature,action=feature_extract(tree,word_vectors,pos_vectors)\n",
    "    train_data.append(feature)\n",
    "    train_data.append(action_vocab[action])\n",
    "\n",
    "train_data=torch.stack(train_data)\n",
    "train_tags=torch.tensor(train_tags)\n",
    "\n",
    "input_size=200\n",
    "hidden_size=200\n",
    "action_size=len(action_vocab)\n",
    "mlp = ScoringFunction(input_size, hidden_size, action_size)\n",
    "\n",
    "model = Parser(mlp)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 1\n",
    "steps=1000\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for i in range(0, len(train_trees)):\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(train_trees[i])\n",
    "        # print(torch.argmax(output))\n",
    "        loss = loss_fn(scores, train_tags[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if i % steps == 0:\n",
    "            print(f\"Epoch {epoch + 1} Train Loss: {total_loss / steps}\")\n",
    "            total_loss = 0\n",
    "            # print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {total_loss:.4f}, Dev Loss: {dev_loss:.4f}')\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for i in range(0, len(dev_trees)):\n",
    "        scores = model(dev_trees[i])\n",
    "        # print(torch.argmax(output))\n",
    "        loss = loss_fn(scores, train_tags[i])\n",
    "        total_loss += loss.item()\n",
    "        if i % steps == 0:\n",
    "            print(f\"Epoch {epoch + 1} Dev Loss: {total_loss / steps}\")\n",
    "            total_loss = 0\n",
    "\n",
    "model_path = \"parser.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
